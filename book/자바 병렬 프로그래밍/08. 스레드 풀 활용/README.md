# 스레드 풀 활용

스레드 풀을 설정하고 튜닝하는 데 사용할 수 있는 고급 옵션을 살펴보고, 작업 실행 프레임웍을 사용할 때 흔히 발생할 수 있는 난관을 헤쳐 나갈 수 있는 방법과 함께 Excutor를 사용하는 고급 예제 몇 가지도
소개한다.

## 8.1 작업과 실행 정책 간의 보이지 않는 연결 관계

Excutor 프레임웍이 작업의 정의 부분과 실행 부분을 서로 분리시켜 줄 수 있다.
하지만 일정 조건을 갖춘 실행 정책이 필요한 작업에는 실행할 수 없는 작업이 있기도 하다.

- **의존성이 있는 작업** <br>
  다른 작업에 의존성을 갖는 작업을 스레드 풀에 올려 실행하려는 경우에는 실행 정책에 보이지 않는 조건을 거는 셈이다. 스레드 풀이 동작하는 동안 활동성 문제가 발생하지 않도록 하려면 실행 정책에 대한 이와 같이
  보이지 않는 조건을 면밀하게 조사하고 관리해야 한다.


- **스레드 한정 기법을 사용하는 작업** <br>
  단일 스레드로 동작하는 스레드 풀은 여러 스레드가 동작하는 경우보다 병렬 프로그램 입장에서 훨씬 안전하게 동작한다.
  단일 스레드로 동작하기 때문에 등록된 작업이 동시에 동작하지 않는다는 점을 보장할 수 있고 따라서 작업 정의 내용을 훨씬 쉽게 구현할 수 있다.
  작업에서 사용하는 객체를 스레드 수준에 맞춰 한정할 수 있으므로 같은 스레드에 한정되어 있는 객체라면 해당 객체가 스레드 안정성을 갖추고 있지 않다해도 얼마든지 마음대로 사용할 수 있다.
  따라서 해당 작업을 실행하려면 Excutor 프레임웍이 단일 스레드로 동작해야 한다는 조건이 생기기 때문에 작업과 실행 정책 간에 보이지 않는 연결 고리가 걸려 있는 상황이다.
  이런 경우에 단일 스레드를 사용하는 풀 대신 여러 개의 스레드를 사용하는 풀로 변경하면 스레드 안정성을 쉽게 잃을 수 있다.


- **응답 시간이 민감한 작업** <br>
  단일 스레드로 동작하는 Excutor에 오랫동안 실행될 작업을 등록하거나 서너개의 스레드로 동작하는 풀에 실행 시간이 긴 작업을 몇 개만 등록하더라도 해당 Excutor를 중심으로 응답 성능이 크게 떨어진다.


- **ThreadLocal을 사용하는 작업** <br>
  ThreadLocal을 사용하면 각 스레드에서 같은 이름의 값을 각자의 버전으로 유지할 수 있다.
  그런데 Excutor는 상황이 되는대로 기존 스레드를 최대한 재사용한다.
  기본으로 포함된 Excutor는 처리해야 할 작업의 수가 적을 때는 쉬고 있는 스레드를 제거하기도 하고, 작업량이 많을 때는 새로운 스레드를 만들어 사용하기도 한다.
  더군다나 작업을 실행하는 도중에 예외가 발생해 스레드를 더 이상 사용하 수 없는 상황에서는 새로운 스레드로 대치시키기도 한다. 스레드 풀에 속한 스레드에서 ThreadLocal을 사용할 때에는 현재 실행 중인
  작업이 끝나면 더 이상 사용하지 않을 값만 보관해야 한다. ThreadLocal을 편법으로 활용해 작업 간에 값을 전달하는 용도로 사용해서는 안 된다.

스레드 풀은 동일하고 서로 독립적인 다수의 작업을 실행할 때 가장 효과적이다.
실행 시간이 오래 걸리는 작업과 금방 끝나는 작업을 섞어서 실행하도록 하면 풀의 크기가 굉장히 크지 않은 한 작업 실행을 방해하는 것과 비슷한 상황이 발생한다.
또한 크기가 제한되어 있는 스레드 풀에 다른 작업의 내용에 의존성을 갖고 있는 작업을 등록하면 데드락이 발생할 가능성이 높다.
다행스럽게도 일번적인 네트워크 기반의 서버 애플리케이션은 작업이 서로 동일하면서 독립적이어야 한다는 조건을 대부분 만족한다.

특정 작업을 실행하고자 할 때 그에 맞는 실행 정책을 요구하는 경우도 있고, 특정 실행 정책 아래에서는 실행되지 않는 경우도 있다.
다른 작업에 의존성이 있는 작업을 실행해야 할 때는 스레드 풀의 크기를 충분히 크게 잡아서 작업이 큐에서 대기하거나 등록되지 못하는 상황이 없도록 해야 한다.
스레드 한정 기법을 사용하는 작업은 반드시 순차적으로 실행돼야 한다.
작업을 구현할 때는 나중에 유지보수를 진행할 때 해당 작업과 호환되지 않는 경우 실행 정책 아래에서 실행되도록 변경해 애플리케이션의 안정성을 해치거나 실행되지 않는 경우를 막을 수 있도록 실행 정책과 관련된 내용을
문서로 남겨야 한다.

### 8.1.1 스레드 부족 데드락

스레드 풀에서 다른 작업에 의존성을 갖고 있는 작업을 실행시킨다면 데드락에 걸릴 가능성이 높다.
단일 스레드로 동작하는 Excutor에서 다른 작업을 큐에 등록하고 해당 작업이 실행된 결과를 가져다 사용하는 작업을 실행하면 데드락이 제대로 걸린다.
이전 작업이 추가한 두 번째 작업은 큐에 쌓인 상태로 이전 작업이 끝나기를 기다릴 것이고 이전 작업은 추가된 작업이 실행되어 그 결과를 알려주기를 기다릴 것이기 때문이다.
스레드 풀의 크기가 크더라도 실행되는 모든 스레드가 큐에 쌓여 아직 실행되지 않은 작업의 결과를 받으려고 대기 중이라면 이와 동일한 상황이 발생할 수 있다.
이런 현상을 바로 스레드 부족 데드락이라고 하며 특정 자원을 확보하고자 계속해서 대기하거나 풀 내부의 다른 작업이 실행돼야 알 수 있는 조건이 만족하기를 기다리는 것처럼 끝없이 계속 대기할 가능성이 있는 기능을
사용하는 작업이 풀에 등록된 경우에는 언제든지 발생할 수 있다.
필요한 작업을 데드락 없이 실행시킬 수 있을 만큼 풀의 크기가 충분히 크다면 물론 문제가 없을 수도 있다.

완전히 독립적이지 않은 작업을 Excutor에 등록할 때는 항상 스레드 부족 데드락이 발생할 수 있다는 사실을 염두에 둬야 하며, 작업을 구현한 코드나 Excutor를 설정하는 설정 파일 등에 항상 스레드 풀의
크기나 설정에 대한 내용을 설명해야 한다.

스레드 풀의 크기는 직접 지정하는 것 이외에도 스레드 풀에서 필요로 하는 자원이 제한되어 원하는 크기보다 작은 수준에서 동작하는 경우도 있다. 예를 들어 애플리케이션에서 10개짜리 JDBC 풀을 사용하며 스레드
풀에서 실행되는 각 작업이 각각 하나씩 JDBC 연결을 사용해야 한다면, 결국은 스레드 풀의 크기가 10보다 크다 해도 실제로 실행될 수 있는 양의 JDBC 풀의 크기인 10개에 불과하다는 점을 주의해야 한다.

### 8.1.2 오래 실행되는 작업

데드락이 발생하지 않는다 하더라도, 특정 작업이 예상보다 긴 시간동안 종료되지 않고 실행된다면 스레드 풀의 응답 속도에 문제점이 생긴다.
오래 실행되는 작업이 있다면 스레드 풀은 전체적인 작업 실행 과정에 어려움을 겪게 되며 금방 끝나는 작업이 실행되는 속도에 영향을 미친다.
오래 실행될 것이라고 예상되는 작업이 대략 몇 개인지를 알고 있을 때 그 개수에 비해 스레드 풀의 크기가 상당히 작은 수준이라면, 시간이 지나면서 스레드 풀에 속한 스레드 가운데 상당수가 오래 실행되는 작업에
잡혀있을 가능성이 크다.
이런 상황에 다다르면 스레드 풀의 응답 속도가 크게 느려진다.

제한 없이 계속해서 대기하는 기능 대신 일정 시간 동안만 대기하는 메소드를 사용할 수 있다면 오래 실행되는 작업이 주는 악영향을 줄일 수 있는 하나의 방법으로 볼 수 있다.
자바 플랫폼 라이브러리에서 제공하는 대부분의 블로킹 메소드는 시간이 제한되지 않은 것과 시간이 제한된 것이 함께 만들어져 있다.
예를 들어 Thread.join 메소드 BlockingQueue.put 메소드, CountDownLatch.await 메소드 Selector.select 메소드 등이 그렇다.
대기하는 도중에 지정한 시간이 지나면 해당 작업이 제대로 실행되지 못했다고 기록해두고 일단 종료시킨 다음 큐의 맨 뒤에 다시 추가하는 등 대책을 세울 수 있다.
이렇게 해두면 성공하건 성공하지 못하건 작업은 뭔가 계속해서 움직이는 모습을 보여줄 것이며, 큐에 쌓여 있던 금방 끝나는 작업을 실행할 수 있도록 스레드를 비워주는 효과가 있다. 스레드 풀을 사용하는 도중에 모든
스레드에서 실행 중인 작업이 대기 상태에 빠지는 경우가 자주 발생한다면, 스레드 풀의 크기가 작다는 것으로 이해할 수도 있다.

## 8.2 스레드 풀 크기 조절

스레드 풀의 가장 이상적인 크기는 스레드 풀에서 실행할 작업의 종류와 스레드 풀을 활용할 애플리케잉션의 특성에 따라 결정된다.
스레드 풀의 크기를 하드코딩해 코정 시키는 것은 그다지 좋은 방법이 아니며, 스레드 풀의 크기는 설정 파일이나 Runtime.availableProcessors 등의 메소드 결과 값에 다라 동적으로 지정되도록 해야
한다.

스레드 풀의 크기를 결정하는 특별한 공식이 있지는 않다.
다만 너무 크거나 너무 작은 등의 극단적인 크기만 아니면 된다.
스레드 풀의 크기가 너무 크게 설정되어 있다면 스레드는 CPU나 메모리 등의 자원을 조금이라도 더 확보하기 위해 경쟁하게 되고, 그러다 보면 CPU에는 부하가 걸리고 메모리는 모자라 금방 자원 부족에 시달릴 것이다.
반대로 스레드 풀의 크기가 너무 작다면 작업량은 계속해서 쌓이는데 CPU나 메모리는 남아돌면서 작업 처리 속도가 떨어질 수 있다.

스레드 풀의 크기를 적절하게 산정하려면 현재 컴퓨터 환경이 어느 정도인지 확인해야 하고, 확보하고 있는 자원의 양도 알아야 하며, 해야 할 작업이 어떻게 동작하는지도 정확하게 알아야 한다.

확인 요소

- 애플리케이션을 실제로 탑재해 동작할 하드웨어 CPU가 몇 개나 꽂혀 있는지?
- 메모리는 얼마나 꽂혀 있는지?
- 실행하는 작업이 CPU 연산을 많이 하는지 아니면 I/O 작업을 많이 하는지?
- 그다지 많이 확보할 수 없는 JDBC 연결과 같은 자원을 얼마나 사용하는지?
- 등...

처리할 작업의 종류가 다양하다면 각자의 작업 부하에 따라 섬세하게 성능을 조절할 수 있도록 여러 개의 스레드 풀을 만들어 활용하는 방법도 사용해볼 수 있다.

CPU를 많이 사용하는 작업의 경우 N개의 CPU를 탑재하고 있는 하드웨어에서 스레드 풀을 사용할 때는 스레드 개수를 N+1개로 맞추면 최적의 성능을 발휘한다고 알려져 있다.
CPU를 많이 사용하는 스레드에서도 페이징 오류가 발생하거나 기타 여러 가지 원인으로 인해 스레드가 멈추는 경우가 있기 때문에 1개의 추가 스레드를 마련해 두면 스레드 가운데 하나에 문제가 발생했을 때 CPU가 쉬지
않고 계속해서 일을 할 수 있다.
I/O 작업이 많거나 기타 다른 블로킹 작업을 해야 하는 경우라면 어느 순간에는 모든 스레드가 대기 상태에 들어가 전체적인 진행이 멈출 수 있기 때문에 스레드 풀의 크기를 훨씬 크게 잡아야 할 필요가 있다.
스레드 풀의 크기를 정하려면 처리해야 할 작업이 시작해서 끝날 때까지 실제 작업하는 시간 대비 대기 시간의 비율을 구해봐야 한다.

물론 스레드 풀을 사용해서 CPU의 사용량만을 조절할 수 있는 것은 아니다.
스레드 풀을 적용하면 메모리, 파일 핸들, 소캣 핸들, 데이터베이스 연결과 같은 자원의 사용량도 적절하게 조절할 수 있다.
CPU가 아닌 이런 자원을 대상으로 하는 스레드 풀의 크기를 정하는 일은 CPU 때보다 훨씬 쉬운데 각 작업에서 실제로 필요한 자원의 양을 모두 더한 값을 자원의 전체 개수로 나눠주면 된다. 
이 값이 바로 스레드 풀의 최대 크기에 해당된다.

스레드 풀에서 동작하는 작업 내부에서 데이터베이스 연결과 같은 자원을 사용해야 한다면 스레드 풀의 크기와 자원 풀의 크기가 서로에게 영향을 미친다.
각 작업 하나가 데이터베이스 연결 하나를 사용한다고 가정하면 스레드 풀의 실제 크기는 데이터베이스 연결 풀의 크기로 제한되는 셈이다.
이와 반대로 데이터베이스 연결을 풀을 특정 스레드 풀에서만 사용한다고 하면 데이터베이스 연결 풀에 확보된 연결 가운데 실제 스레드 풀의 크기에 해당하는 연결만 사용될 것이다.


## 8.3 ThreadPoolExecutor 설정
ThreadPoolExecutor는 Executors 클래스에 들어 있는 newCachedThreadPool, newFixedThreadPool, newScheduledThreadPool과 같은 팩토리 메소드에서 생성해주는 Executor에 대한 기본적인 내용이 구현되어 있는 클래스이다.
ThreadPoolExecutor 클래스는 유연하면서도 안정적이고 여러 가지 설정을 통해 입맛에 맞게 바꿔 사용할 수 있도록 되어 있다.

팩토리 메소드를 사용해 만들어진 스레드 풀의 기본 실행 정책이 요구사항에 잘 맞지 않는다면 ThreadPoolExecutor 클래스의 생성 메소드를 직접 호출해 스레드 풀을 생성할 수 있으며 생성 메소드에 넘겨주는 값을 통해 스레드 풀의 설정을 마음대로 조절할 수 있다.
자바 플랫폼에 들어 있는 Executors 클래스의 소스코드를 들여다 보면 각종 기본 팩토리 메소드에서 ThreadPoolExecutor 클래스에 어떤 설정을 적용하는지 쉽게 알아볼 수 있으니 참조하자.
ThreadPoolExecutor 클래스에는 생성 메소드가 여러 개 있다.

### 8.3.1 스레드 생성과 제거
풀의 코어 크기나 최대 크기 스레드 유지 시간 등의 값을 통해 스레드가 생성되고 제거되는 과정을 조절할 수 있다. 

``` java
public ThreadPoolExecutor (
  int corePoolSize,
  int maximumPoolSize,
  long keepAliveTime,
  TimeUnit unit,
  BlockingQueue<Runnable> workQueue,
  ThreadFactory threadFactory,
  RejectedExecutionHandler handler) {
  ... 
}
```

- **ThreadPoolExecutor** 메소드 설정 값
  - **corePoolSize** <br>
  스레드 풀을 사용할 때 원하는 스레드의 개수라고 볼 수 있다. 스레드 풀 클래스는 실행할 작업이 없다 하더라도 스레드의 개수를 최대한 코어 크기에 맞추도록 되어 있다. 또한 큐에 작업이 가득 차지 않는 이상 스레드의 수가 코어 크기를 넘지 않는다.
  - **maximumPoolSize** <br>
  풀의 최대 크기는 동시에 얼마나 많은 개수의 스레드가 동작할 수 있는지를 제한하는 최대 값이다.
  - **keepAliveTime** <br> 
  지정한 스레드 유지 시간 이상 아무런 작업 없이 대기하고 있던 스레드는 제거 대상 목록에 올라가며, 풀의 스레드 개수가 코어 크기를 넘어설 때 제거될 수 있다. 따라서 코어 크기와 스레드 유지 시간을 적절하게 조절하면 작업 없이 쉬고 있는 스레드가 차지하고 있는 자원을 프로그램의 다른 부분에서 활용하게 반납하도록 할 수 있다. 하지만 스레드를 한 번 종료하고 나면 나중에 스레드가 필요해 생성해야 하는 시점에 스레드를 생성하는 만큼의 시간이 더 필요한 단점이 있다.


- **ThreadPoolExecutor** 팩토리 메소드
  - **newFixedThreadPool** <br>
  newFixedThreadPool 팩토리 메소드는 결과로 생성할 스레드 풀의 코어 크기를 최대 newFixedThreadPool 메소드에 지정한 값으로 동일하게 지정하며, 시간제한은 무제한으로 설정되는 것과 같다.
  - **newCachedThreadPool** <br>
    newCachedThreadPool 팩토리 메소드는 스레드 풀의 최대 크기를 Integer.MAX_VALUE 값으로 지정하고 코어 크기를 0으로, 스레드 유지 시간을 1분으로 지정한다. 따라서 newCachedThreadPool에서 만들어 낸 스레드 풀은 끝없이 크기가 늘어날 수 있으며 사용량이 줄어들면 스레드 개수가 적당히 줄어드는 효과가 있다.


### 8.3.2 큐에 쌓인 작업 관리
크기가 제한된 스레드 풀에서는 동시에 실행될 수 있는 스레드의 개수가 제한되어 있다.
고정된 크기의 스레드 풀을 사용하더라도 애플리케이션에 부하가 많이 걸리는 경우에는 자원을 모두 잡아먹는 상태에 이를 수 있으며, 단지 스레드 풀을 사용하지 않는 경우보다 문제가 훨씬 적게 발생할 뿐이다.
작업을 처리할 수 있는 능력보다 많은 양의 요청이 들어오면 처리하지 못한 요청이 큐에 계속해서 쌓인다.
스레드 풀을 사용하는 경우에는 Executor 클래스에서 관리하는 큐에 Runnable로 정의된 작업이 계속해서 쌓일 뿐이며, 스레드 풀 없이 스레드가 계속해서 생성됐을 때 각 스레드가 CPU를 확보하기 위해 대기하는 것과 다를 바 없는 상황이 발생한다.
대기 중인 작업을 Runnable로 표현하고 Runnable의 묶음을 List 형태로 관리하면 스레드를 생성하는 것보다 자원을 덜 소모하기는 하지만, 애플리케이션이 처리할 수 있는 것보다 많은 양의 작업이 들어올 때 시스템 자원이 모자라는 것은 같다는 말이다.

일반적인 경우에는 작업이 추가되는 속도가 굉장이 일정한 편이지만, 간혹 어느 순간에 한꺼번에 대량의 작업이 추가되기도 한다.
큐를 사용하면 대량의 작업이 갑자기 들어오는 경우에 좀더 유연하게 대응할 수 있기는 하지만, 계속해서 처리하는 속도보다 빠른 속도로 작업이 추가되면 속도 조절 기능을 사용해 메모리가 가득 차는 현상을 막야 할 것이다.
아직 메모리 공간에 공간이 남아 가득 찬 상태가 아니라 하더라도 큐에 작업이 쌓이면 쌓일수록 작업을 처리해주는 시간은 점점 길어질 것이다.

ThreadPoolExecutor를 생성할 때 작업에 쌓아둘 큐로 BlockingQueue를 지정할 수 있다.
스레드 풀에서 작업을 쌓아둘 큐에 적용할 수 있는 전략은 세 가지가 있다.
1. 큐에 크기 제한을 두지 않는 방법
2. 큐의 크기를 제한하는 방법
3. 작업을 스레드에게 직접 넘겨주는 방법

작업을 쌓는 방식 역시 풀의 크기를 지정하는 것과 같은 여러가지 설정과 연관되어 있다.
newFixedThreadPool 메소드와 newSingleThreadExecutor 메소드에서 생성하는 풀은 기본 설정으로 크기가 제한되지 않은 LinkedBlockingQueue를 사용한다. 
스레드 풀의 모든 작업 스레드가 실행 중일 때 작업이 등록되면 해당 작업은 큐에 쌓이게 되며, 작업이 처리되는 속도보다 작업이 추가되는 속도가 빠르면 큐에 끝없이 계속해서 작업이 쌓일 수 있다.

자원 관리 측면에서 ArrayBlockingQueue 또는 크기가 제한된 LinkedBlockingQueue 나 PriorityBlockingQueue 와 같이 큐의 크기를 제한시켜 사용하는 방법이 훨씬 안정적이다.
크기가 제한된 큐를 사용하면 자원 사용량을 한정시킬 수 있다는 장점이 있지만, 큐가 가득 찼을 때 새로운 작업을 등록하려는 상황을 어떻게 처리해야 하는지에 대한 문제가 생긴다. 
작업 큐의 크기를 제한한 상태에서는 큐의 크기와 스레드의 개수를 동시에 튜닝해야 한다.
스레드의 개수를 줄이면서 큐의 크기를 늘려주면 메모리와 CPU 사용량을 줄이면서 컨텍스트 스위칭 횟수를 줄일 수 있지만 전체적인 성능에는 제한이 생길 수 있다.

스레드 개수가 굉장히 많거나 제한이 거의 없는 상태인 경우에는 작업을 큐에 쌓는 절차를 생략할 수도 있을텐데, 이럴때는 SynchronousQueue를 사용해 프로듀서에서 생성한 작업을 컨슈머인 스레드에게 직접 전달할 수 있다.
SynchronousQueue는 따지고 보면 큐가 아니며 단지 스레드 간에 작업을 넘겨주는 기능을 담당한다고 볼 수 있다.
SynchronousQueue에 작업을 추가하려면 컨슈머인 스레드가 이미 작업을 받기 위해 대기하고 있어야만 한다.
대기 중인 스레드가 없는 상태에서 스레드의 개수가 최대 크기보다 작다면 ThreadPoolExecutor는 새로운 스레드를 생성해 동작시킨다.
반면 스레드의 개수가 최대 크기에 다다른 상태라면 집중 대응 정책에 따라 작업을 거부하도록 되어 있다.
처리할 작업을 큐에 일단 쌓고 쌓인 작업을 쉬는 스레드가 가져가도록 하는 것보다 쉬고 있는 스레드에게 처리할 작업을 직접 넘겨주는 방법이 있다면 훨씬 효율적일 수 있다.
SynchronousQueue는 스레드의 개수가 제한이 없는 상태이거나 넘치는 작업을 마음대로 거부할 수 있는 상황이어야 적용할만한 방법이다.
newCachedThreadPool 팩토리 메소드에서는 스레드 풀에 SynchronousQueue를 적용한다.

LinkedBlockingQueue나 ArrayBlockingQueue와 같은 FIFO 큐를 사용하면 작업이 등록된 순서에 맞춰 실행된다.
작업이 실행되는 순서를 좀더 조절하고자 한다면 PriorityBlockingQueue를 사용해 작업에 지정된 우선 순위에 따라 실행되도록 할 수 있다.
작업의 우선 순위는 기본 순서를 따르거나 Comparator를 지정해 원하는 순서로 배치할 수 있다.

크기가 고정된 풀보다는 newCachedThreadPool 팩토리 메소드가 생성해주는 Executor가 나은 선택일 수 있다.
크기가 고정된 스레드 풀은 자원 관리 측면에서 동시에 실행되는 스레드의 수를 제한해야 하는 경우에 현명한 선택이 될 수 있다.
예를 들어 네트워크로 클라이언트의 요청을 받아 처리하는 애플리케이션과 같은 경우 크기가 고정되어 있지 않다면 요청이 많아져 부하가 걸릴 때 문제가 커진다.

스레드 풀에서 실행할 작업이 서로 독립적인 경우에만 스레드의 개수나 작업 큐의 크기를 제한할 수 있다.
다른 작업에 의존성을 갖는 작업을 실행해야 할 때 스레드나 큐의 크기가 제한되어 있다면 스레드 부족 데드락에 걸릴 가능성이 높다.
이럴 때는 newCachedThreadPool 메소드에서 생성하는 것과 같이 크기가 제한되지 않은 풀을 사용해야 한다.

### 8.3.3 집중 대응 정책
크기가 제한된 큐에 작업이 가득 차면 집중 대응 정책이 동작한다.
ThreadPoolExecutor의 집중 대응 정책은 setRejectedExecutionHandler 메소드를 사용해 원하는 정책으로 변경할 수 있다.
여러 가지 종류의 RejectedExecutionHandler를 사용해 다양한 집중 대응 정책을 적용할 수 있다.
RejectedExecutionHandler에는 AbortPolicy, CallerRunsPolicy, DiscardPolicy, DiscardOldestPolicy 등이 있다.

기본적으로 사용하는 집중 대응 정책은 중단 정책이며 execute 메소드에서 RuntimeException을 상속받은 RejectedExecutionException을 던진다.
execute 메소드를 호출하는 스레드는 RejectedExecutionException을 잡아서 작업을 더 이상 추가할 수 없는 상황에 직접 대응해야 한다.
제거 정책은 큐에 작업을 더 이상 쌓을 수 없다면 방금 추가시키려고 했던 정책을 아무 반응 없이 제거해버린다.
이와 비슷한 오래된 항목 제거 정책은 큐에 쌓은 항목 중 가장 오래되어 다음 번에 실행될 예정이던 작업을 제거하고, 추가하고자 했던 작업을 큐에 다시 추가해본다.
작업 큐가 우선 순위에 따라 동작한다면 오래된 항목 제거 정책의 경우 우선 순위가 가장 높은 항목을 제거한다. 따라서 오래된 항목을 제거하는 정책과 함께 작업 큐로 우선 순위 큐를 사용하는 것은 좋지 않다.

호출자 실행 정책은 작업을 제거해 버리거나 예외를 던지지 않으면서 큐의 크기를 초과하는 작업을 프로듀서에게 거꾸로 넘겨 작업 추가 속도를 늦출 수 있도록 일종의 속도 조절 방법으로 사용된다.
다시 말해 새로 등록하려고 했던 작업을 스레드 풀의 작업 스레드로 실행하지 않고 execute 메소드를 호출해 작업을 등록하려 했던 스레드에서 실행시킨다.
프로듀서인 메인 스레드가 추가하려던 작업을 직접 처리하게 되면, 해당 작업 하나를 실행하는 동안에는 또 다른 새 작업을 추가할 수 없으므로 자연스럽게 스레드 풀이 큐에 쌓인 작업을 처리할 시간을 약간 벌 수 있다.
웹 서버의 메인 스레드가 직접 작업을 처리하기 때문에 소켓의 accept 메소드도 호출할 수 없으므로 원격 클라이언트가 접속했을 때 네트워크로 누군가 접속했다는 사실을 웹 서버 프로그램이 알기 전에 웹 서버보다 훨씬 낮은 TCP 계층에서 해당 접속 요청을 자체 큐에 쌓아 대기시킨다.
TCP 계층의 큐에도 네트워크 접속 요청이 계속해서 쌓이다 보면 TCP 계층 역시 더 이상의 연결을 큐에 쌓지 못하고 연결 요청을 거부하기 시작한다.
이처럼 웹 서버에 부하가 걸리기 시작하면 부하가 웹 서버 내부에서 밖으로 드러나기 시작한다.
가장 먼저 웹 서버 내부 스레드 풀에서 부하가 나타나고 서버가 동작하는 시스템 TCP 계층에서 부하가 나타나며 결국 클라이언트가 부하를 직접 느끼게 된다.
이렇게 여러 단계를 거쳐 부하가 전달되기 때문에 부하가 걸린 상태에서도 애플리케이션의 전체적인 성능이 점진적으로 떨어지도록 조절할 수 있다.

스레드 풀에 적용할 집중 대응 정책을 선택하거나 실행 정책의 다른 여러 가지 설정을 변경하는 일은 모두 Executor를 생성할 때 지정할 수 있다.

### 8.3.4 스레드 팩토리
